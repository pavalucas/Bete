{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36db7762-c582-4d24-9a10-60f15f2c5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import spacy\n",
    "import pandas as pd\n",
    "# !spacy download pt_core_news_lg\n",
    "from dataset import Data, DataBERT\n",
    "from transformers import AutoTokenizer\n",
    "from model import CRF, LinearLayerCRF, BERTSlotFilling\n",
    "from evaluation import Evaluation\n",
    "from trainer import Trainer\n",
    "from random import Random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea10344-2bfc-4270-8b43-9e5908155efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General constants\n",
    "NUM_EXPERIMENTS = 1\n",
    "OUTPUT_PATH = 'output_files/'\n",
    "DATA_PATH = '../../data/curated_dataset_2021_10_15.csv'\n",
    "\n",
    "# Linear Layer + CRF constants\n",
    "NUM_EPOCHS = 10\n",
    "BATCH = 2\n",
    "\n",
    "# BERT constants\n",
    "HIDDEN_DIM = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983aa753-476b-456a-bdfb-b778352172c7",
   "metadata": {},
   "source": [
    "# Doing the same with the new dataset format from WebAnno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df274890-1a81-412d-8f42-7e96b5caafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_diabete(path_dir):\n",
    "    nlp = spacy.load(\"pt_core_news_lg\")\n",
    "    df = pd.read_csv(path_dir)\n",
    "    file_name_list = list(df['File'].unique())\n",
    "    corpus, vocab_in, vocab_out = [], ['PAD', 'UNK'], []\n",
    "    for file_name in file_name_list:\n",
    "        print(file_name)\n",
    "        file_df = df[df['File'] == file_name]\n",
    "        tokens = list(file_df['Token'])\n",
    "        \n",
    "        # TODO get postag of each token -> I should get postag of whole text instead\n",
    "#         text = ' '.join(tokens)\n",
    "#         doc = nlp(text)\n",
    "        postag = [nlp(token)[0].pos_ for token in tokens]\n",
    "        \n",
    "        # put tags in IOB2 format\n",
    "        file_tags = list(file_df['Entity'])\n",
    "        cur_tag = ''\n",
    "        tags = []\n",
    "        for file_tag in file_tags:\n",
    "            # remove number at the end of file tag\n",
    "            tag = file_tag.split('[')[0]\n",
    "            if file_tag == '_':\n",
    "                tags.append('O')\n",
    "            elif file_tag != cur_tag:\n",
    "                tags.append('B-' + tag)\n",
    "                cur_tag = file_tag\n",
    "            else:\n",
    "                tags.append('I-' + tag)\n",
    "\n",
    "        assert len(tokens) == len(postag)\n",
    "        corpus.append({'tokens': tokens, 'tags': tags, 'postags': postag})\n",
    "        vocab_in.extend(tokens)\n",
    "        vocab_out.extend(tags)\n",
    "        \n",
    "    vocab_in = set(vocab_in)\n",
    "    in_w2id = {w: i for i, w in enumerate(vocab_in)}\n",
    "    in_id2w = {i: w for i, w in enumerate(vocab_in)}\n",
    "\n",
    "    vocab_out = set(vocab_out)\n",
    "    out_w2id = {w: i for i, w in enumerate(vocab_out)}\n",
    "    out_id2w = {i: w for i, w in enumerate(vocab_out)}\n",
    "    return corpus, vocab_in, in_w2id, in_id2w, vocab_out, out_w2id, out_id2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca599080-c2dc-4946-bd65-c0329b706a6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resposta_0001.txt\n",
      "resposta_0002.txt\n",
      "resposta_0003.txt\n",
      "resposta_0004.txt\n",
      "resposta_0005.txt\n",
      "resposta_0006.txt\n",
      "resposta_0007.txt\n",
      "resposta_0008.txt\n",
      "resposta_0009.txt\n",
      "resposta_0010.txt\n",
      "resposta_0011.txt\n",
      "resposta_0012.txt\n",
      "resposta_0013.txt\n",
      "resposta_0014.txt\n",
      "resposta_0015.txt\n",
      "resposta_0016.txt\n",
      "resposta_0017.txt\n",
      "resposta_0018.txt\n",
      "resposta_0019.txt\n",
      "resposta_0020.txt\n",
      "resposta_0021.txt\n",
      "resposta_0022.txt\n",
      "resposta_0023.txt\n",
      "resposta_0024.txt\n",
      "resposta_0025.txt\n",
      "resposta_0026.txt\n",
      "resposta_0027.txt\n",
      "resposta_0028.txt\n",
      "resposta_0029.txt\n",
      "resposta_0030.txt\n",
      "resposta_0031.txt\n",
      "resposta_0032.txt\n",
      "resposta_0033.txt\n",
      "resposta_0034.txt\n",
      "resposta_0035.txt\n",
      "resposta_0036.txt\n",
      "resposta_0037.txt\n",
      "resposta_0038.txt\n",
      "resposta_0039.txt\n",
      "resposta_0040.txt\n",
      "resposta_0041.txt\n",
      "resposta_0042.txt\n",
      "resposta_0043.txt\n",
      "resposta_0044.txt\n",
      "resposta_0045.txt\n",
      "resposta_0046.txt\n",
      "resposta_0047.txt\n",
      "resposta_0048.txt\n",
      "resposta_0049.txt\n",
      "resposta_0050.txt\n",
      "resposta_0051.txt\n",
      "resposta_0052.txt\n",
      "resposta_0053.txt\n",
      "resposta_0054.txt\n",
      "resposta_0055.txt\n",
      "resposta_0056.txt\n",
      "resposta_0057.txt\n",
      "resposta_0058.txt\n",
      "resposta_0059.txt\n",
      "resposta_0060.txt\n",
      "resposta_0061.txt\n",
      "resposta_0062.txt\n",
      "resposta_0063.txt\n",
      "resposta_0064.txt\n",
      "resposta_0065.txt\n",
      "resposta_0066.txt\n",
      "resposta_0067.txt\n",
      "resposta_0068.txt\n",
      "resposta_0069.txt\n",
      "resposta_0070.txt\n",
      "resposta_0071.txt\n",
      "resposta_0072.txt\n",
      "resposta_0073.txt\n",
      "resposta_0074.txt\n",
      "resposta_0075.txt\n",
      "resposta_0076.txt\n",
      "resposta_0077.txt\n",
      "resposta_0078.txt\n",
      "resposta_0079.txt\n",
      "resposta_0080.txt\n",
      "resposta_0081.txt\n",
      "resposta_0082.txt\n",
      "resposta_0083.txt\n",
      "resposta_0084.txt\n",
      "resposta_0085.txt\n",
      "resposta_0086.txt\n",
      "resposta_0087.txt\n",
      "resposta_0088.txt\n",
      "resposta_0089.txt\n",
      "resposta_0090.txt\n",
      "resposta_0091.txt\n",
      "resposta_0092.txt\n",
      "resposta_0093.txt\n",
      "resposta_0094.txt\n",
      "resposta_0095.txt\n",
      "resposta_0096.txt\n",
      "resposta_0097.txt\n",
      "resposta_0098.txt\n",
      "resposta_0099.txt\n",
      "resposta_0100.txt\n",
      "resposta_0101.txt\n",
      "resposta_0102.txt\n",
      "resposta_0103.txt\n",
      "resposta_0104.txt\n",
      "resposta_0105.txt\n",
      "resposta_0106.txt\n",
      "resposta_0107.txt\n",
      "resposta_0108.txt\n",
      "resposta_0109.txt\n",
      "resposta_0110.txt\n",
      "resposta_0111.txt\n",
      "resposta_0112.txt\n",
      "resposta_0113.txt\n",
      "resposta_0114.txt\n",
      "resposta_0115.txt\n",
      "resposta_0116.txt\n",
      "resposta_0117.txt\n",
      "resposta_0118.txt\n",
      "resposta_0119.txt\n",
      "resposta_0120.txt\n",
      "resposta_0121.txt\n",
      "resposta_0122.txt\n",
      "resposta_0123.txt\n",
      "resposta_0124.txt\n",
      "resposta_0125.txt\n",
      "resposta_0126.txt\n",
      "resposta_0127.txt\n",
      "resposta_0128.txt\n",
      "resposta_0129.txt\n",
      "resposta_0130.txt\n",
      "resposta_0131.txt\n",
      "resposta_0132.txt\n",
      "resposta_0133.txt\n",
      "resposta_0134.txt\n",
      "resposta_0135.txt\n",
      "resposta_0136.txt\n",
      "resposta_0137.txt\n",
      "resposta_0138.txt\n",
      "resposta_0139.txt\n",
      "resposta_0140.txt\n",
      "resposta_0141.txt\n",
      "resposta_0142.txt\n",
      "resposta_0143.txt\n",
      "resposta_0144.txt\n",
      "resposta_0145.txt\n",
      "resposta_0146.txt\n",
      "resposta_0147.txt\n",
      "resposta_0148.txt\n",
      "resposta_0149.txt\n",
      "resposta_0150.txt\n",
      "resposta_0151.txt\n",
      "resposta_0152.txt\n",
      "resposta_0153.txt\n",
      "resposta_0154.txt\n",
      "resposta_0155.txt\n",
      "resposta_0156.txt\n",
      "resposta_0157.txt\n",
      "resposta_0158.txt\n",
      "resposta_0159.txt\n",
      "resposta_0160.txt\n",
      "resposta_0161.txt\n",
      "resposta_0162.txt\n",
      "resposta_0163.txt\n",
      "resposta_0164.txt\n",
      "resposta_0165.txt\n",
      "resposta_0166.txt\n",
      "resposta_0167.txt\n",
      "resposta_0168.txt\n",
      "resposta_0169.txt\n",
      "resposta_0170.txt\n",
      "resposta_0171.txt\n",
      "resposta_0172.txt\n",
      "resposta_0173.txt\n",
      "resposta_0174.txt\n",
      "resposta_0175.txt\n",
      "resposta_0176.txt\n",
      "resposta_0177.txt\n",
      "resposta_0178.txt\n",
      "resposta_0179.txt\n",
      "resposta_0180.txt\n",
      "resposta_0181.txt\n",
      "resposta_0182.txt\n",
      "resposta_0183.txt\n",
      "resposta_0184.txt\n",
      "resposta_0185.txt\n",
      "resposta_0186.txt\n",
      "resposta_0187.txt\n",
      "resposta_0188.txt\n",
      "resposta_0189.txt\n",
      "resposta_0190.txt\n",
      "resposta_0191.txt\n",
      "resposta_0192.txt\n",
      "resposta_0193.txt\n",
      "resposta_0194.txt\n",
      "resposta_0195.txt\n",
      "resposta_0196.txt\n",
      "resposta_0197.txt\n",
      "resposta_0198.txt\n",
      "resposta_0199.txt\n",
      "resposta_0200.txt\n",
      "resposta_0201.txt\n",
      "resposta_0202.txt\n",
      "resposta_0203.txt\n",
      "resposta_0204.txt\n",
      "resposta_0205.txt\n",
      "resposta_0206.txt\n",
      "resposta_0207.txt\n",
      "resposta_0208.txt\n",
      "resposta_0209.txt\n",
      "resposta_0210.txt\n",
      "resposta_0211.txt\n",
      "resposta_0212.txt\n",
      "resposta_0213.txt\n",
      "resposta_0214.txt\n",
      "resposta_0215.txt\n",
      "resposta_0216.txt\n",
      "resposta_0217.txt\n",
      "resposta_0218.txt\n",
      "resposta_0219.txt\n",
      "resposta_0220.txt\n",
      "resposta_0221.txt\n",
      "resposta_0222.txt\n",
      "resposta_0223.txt\n",
      "resposta_0224.txt\n",
      "resposta_0225.txt\n",
      "resposta_0226.txt\n",
      "resposta_0227.txt\n",
      "resposta_0228.txt\n",
      "resposta_0229.txt\n",
      "resposta_0230.txt\n",
      "resposta_0231.txt\n",
      "resposta_0232.txt\n",
      "resposta_0233.txt\n",
      "resposta_0234.txt\n",
      "resposta_0235.txt\n",
      "resposta_0236.txt\n",
      "resposta_0237.txt\n",
      "resposta_0238.txt\n",
      "resposta_0239.txt\n",
      "resposta_0240.txt\n",
      "resposta_0241.txt\n",
      "resposta_0242.txt\n",
      "resposta_0243.txt\n",
      "resposta_0244.txt\n",
      "resposta_0245.txt\n",
      "resposta_0246.txt\n",
      "resposta_0247.txt\n",
      "resposta_0248.txt\n",
      "resposta_0249.txt\n",
      "resposta_0250.txt\n",
      "resposta_0251.txt\n",
      "resposta_0252.txt\n",
      "resposta_0253.txt\n",
      "resposta_0254.txt\n",
      "resposta_0255.txt\n",
      "resposta_0256.txt\n",
      "resposta_0257.txt\n",
      "resposta_0258.txt\n",
      "resposta_0259.txt\n",
      "resposta_0260.txt\n",
      "resposta_0261.txt\n",
      "resposta_0262.txt\n",
      "resposta_0263.txt\n",
      "resposta_0264.txt\n",
      "resposta_0265.txt\n",
      "resposta_0266.txt\n",
      "resposta_0267.txt\n",
      "resposta_0268.txt\n",
      "resposta_0269.txt\n",
      "resposta_0270.txt\n",
      "resposta_0271.txt\n",
      "resposta_0272.txt\n",
      "resposta_0273.txt\n",
      "resposta_0274.txt\n",
      "resposta_0275.txt\n",
      "resposta_0276.txt\n",
      "resposta_0277.txt\n",
      "resposta_0278.txt\n",
      "resposta_0279.txt\n",
      "resposta_0280.txt\n",
      "resposta_0281.txt\n",
      "resposta_0282.txt\n",
      "resposta_0283.txt\n",
      "resposta_0284.txt\n",
      "resposta_0285.txt\n",
      "resposta_0286.txt\n",
      "resposta_0287.txt\n",
      "resposta_0288.txt\n",
      "resposta_0289.txt\n",
      "resposta_0290.txt\n",
      "resposta_0291.txt\n",
      "resposta_0292.txt\n",
      "resposta_0293.txt\n",
      "resposta_0294.txt\n",
      "resposta_0295.txt\n",
      "resposta_0296.txt\n",
      "resposta_0297.txt\n",
      "resposta_0298.txt\n",
      "resposta_0299.txt\n",
      "resposta_0300.txt\n",
      "resposta_0301.txt\n",
      "resposta_0302.txt\n",
      "resposta_0303.txt\n",
      "resposta_0304.txt\n"
     ]
    }
   ],
   "source": [
    "corpus = load_data_diabete(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50eb3e0-31f8-40f9-a587-3393adf6d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocab_in, in_w2id, in_id2w, vocab_out, out_w2id, out_id2w = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519069f3-dcf9-49df-8cca-5f0f02c42c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 244\n",
      "Dev: 30\n",
      "Test: 30\n"
     ]
    }
   ],
   "source": [
    "size = int(0.1 * len(corpus))\n",
    "Random(42).shuffle(corpus)\n",
    "dev_data = corpus[:size]\n",
    "test_data = corpus[size:(2*size)]\n",
    "train_data = corpus[(2*size):]\n",
    "print(f'Train: {len(train_data)}')\n",
    "print(f'Dev: {len(dev_data)}')\n",
    "print(f'Test: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12336d77-b731-43b4-bcce-a90b5fd5b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_data, open('../../data/train/train.pkl', 'wb'))\n",
    "pickle.dump(dev_data, open('../../data/dev/dev.pkl', 'wb'))\n",
    "pickle.dump(test_data, open('../../data/test/test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a88fa2-f5ec-41fe-a606-bb755ba9ee10",
   "metadata": {},
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2035a57-8373-4536-a6e5-201786ba1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#           CRF\n",
    "################################################\n",
    "time_str = time.strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "crf_output_folder = OUTPUT_PATH + ('crf_%s' % time_str) + '/'\n",
    "if not os.path.exists(crf_output_folder):\n",
    "    os.makedirs(crf_output_folder)\n",
    "data_info = Data(DATA_PATH)\n",
    "crf = CRF()\n",
    "evaluation = Evaluation(crf_output_folder)\n",
    "\n",
    "print(\"Evaluating CRF:\")\n",
    "micro_avg_f1 = 0.0\n",
    "y_true = y_pred = test_tokens = []\n",
    "for num_experiment in range(NUM_EXPERIMENTS):\n",
    "    x_train, y_train, x_test, y_true, test_tokens = crf.get_train_test_data(data_info)\n",
    "    crf.fit(x_train, y_train)\n",
    "    y_pred = crf.predict(x_test)\n",
    "    print(x_test)\n",
    "    print(y_true)\n",
    "    micro_avg_f1 += evaluation.evaluate(num_experiment, y_true, y_pred)\n",
    "micro_avg_f1 /= NUM_EXPERIMENTS\n",
    "print()\n",
    "print('\\tMicro average F1: %.2f' % micro_avg_f1)\n",
    "\n",
    "evaluation.generate_output_csv('crf_output', y_true, y_pred, test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a573730-bac8-48e0-90f8-40538e991a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#           Linear Layer + CRF\n",
    "################################################\n",
    "time_str = time.strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "linear_layer_crf_output_folder = OUTPUT_PATH + ('linear_layer_crf_%s' % time_str) + '/'\n",
    "if not os.path.exists(linear_layer_crf_output_folder):\n",
    "    os.makedirs(linear_layer_crf_output_folder)\n",
    "\n",
    "data_info = Data(DATA_PATH)\n",
    "train_data, test_data = data_info.fit()\n",
    "vocab_size = len(data_info.vocab_in)\n",
    "num_classes = len(data_info.vocab_out)\n",
    "\n",
    "model = LinearLayerCRF(num_classes, vocab_size, data_info.out_w2id)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "trainer = Trainer(model, BATCH, is_bert=False)\n",
    "evaluation = Evaluation(linear_layer_crf_output_folder)\n",
    "\n",
    "micro_avg_f1 = 0.0\n",
    "y_true_text = y_pred_text = test_tokens = []\n",
    "for num_experiment in range(NUM_EXPERIMENTS):\n",
    "    y_true, y_pred = trainer.test(test_data)\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        trainer.train(train_data, optimizer, epoch)\n",
    "        y_true, y_pred = trainer.test(test_data)\n",
    "\n",
    "    # get test tokens and convert output from number to text\n",
    "    test_tokens = [info[-1] for info in test_data]\n",
    "    y_true_text = evaluation.convert_output_to_text(y_true, data_info.out_id2w)\n",
    "    y_pred_text = evaluation.convert_output_to_text(y_pred, data_info.out_id2w)\n",
    "\n",
    "    micro_avg_f1 += evaluation.evaluate(num_experiment, y_true_text, y_pred_text)\n",
    "\n",
    "micro_avg_f1 /= NUM_EXPERIMENTS\n",
    "print()\n",
    "print('Micro avg F1: %.2f' % micro_avg_f1)\n",
    "evaluation.generate_output_csv('linear_layer_output', y_true_text, y_pred_text, test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f056c131-55f4-4d10-b4e3-d5b63621b7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-large-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 3.278683\n",
      "Train Epoch: 2 \tLoss: 3.131175\n",
      "Train Epoch: 3 \tLoss: 2.919506\n",
      "Train Epoch: 4 \tLoss: 2.833187\n",
      "Train Epoch: 5 \tLoss: 2.775946\n",
      "Train Epoch: 6 \tLoss: 2.743813\n",
      "Train Epoch: 7 \tLoss: 2.714914\n",
      "Train Epoch: 8 \tLoss: 2.678570\n",
      "Train Epoch: 9 \tLoss: 2.654851\n",
      "Train Epoch: 10 \tLoss: 2.646982\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       Complication       0.49      0.80      0.61        45\n",
      "       DiabetesType       0.00      0.00      0.00         8\n",
      "           Duration       0.00      0.00      0.00         1\n",
      "               Food       0.36      0.82      0.50        11\n",
      "       GlucoseValue       0.14      0.22      0.17        27\n",
      "            Insulin       0.00      0.00      0.00         7\n",
      "         Medication       0.14      0.60      0.23         5\n",
      "NonMedicalTreatment       0.22      0.83      0.35        18\n",
      "                Set       0.00      0.00      0.00         1\n",
      "            Symptom       0.32      0.31      0.32        39\n",
      "               Test       0.08      0.11      0.09         9\n",
      "               Time       0.00      0.00      0.00         4\n",
      "\n",
      "          micro avg       0.29      0.47      0.36       175\n",
      "          macro avg       0.15      0.31      0.19       175\n",
      "       weighted avg       0.27      0.47      0.33       175\n",
      "\n",
      "\n",
      "Micro avg F1: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.conda/envs/opendomainchat/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#           BERT\n",
    "################################################\n",
    "time_str = time.strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "bert_output_folder = OUTPUT_PATH + ('bert_%s' % time_str) + '/'\n",
    "if not os.path.exists(bert_output_folder):\n",
    "    os.makedirs(bert_output_folder)\n",
    "\n",
    "data_info = DataBERT(DATA_PATH)\n",
    "train_data, test_data = data_info.fit()\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "num_classes = len(data_info.vocab_out)\n",
    "model = BERTSlotFilling(HIDDEN_DIM, num_classes, device=device)\n",
    "model.to(device)\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = optim.Adam(optimizer_grouped_parameters, lr=1e-5)\n",
    "weights = [1.] * num_classes\n",
    "weights[data_info.out_w2id['O']] = 0.01\n",
    "weights = torch.tensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "evaluation = Evaluation(bert_output_folder)\n",
    "trainer = Trainer(model, BATCH, is_bert=True, criterion=criterion, device=device)\n",
    "\n",
    "micro_avg_f1 = 0.0\n",
    "y_true_text = y_pred_text = test_tokens = []\n",
    "for num_experiment in range(NUM_EXPERIMENTS):\n",
    "    y_true, y_pred = trainer.test(test_data)\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        trainer.train(train_data, optimizer, epoch)\n",
    "        y_true, y_pred = trainer.test(test_data)\n",
    "\n",
    "    # get test tokens and convert output from number to text\n",
    "    test_tokens = [info[-1] for info in test_data]\n",
    "    y_true_text = evaluation.convert_output_to_text(y_true, data_info.out_id2w)\n",
    "    y_pred_text = evaluation.convert_output_to_text(y_pred, data_info.out_id2w)\n",
    "\n",
    "    micro_avg_f1 += evaluation.evaluate(num_experiment, y_true_text, y_pred_text)\n",
    "\n",
    "micro_avg_f1 /= NUM_EXPERIMENTS\n",
    "print()\n",
    "print('Micro avg F1: %.2f' % micro_avg_f1)\n",
    "evaluation.generate_output_csv('bert_output', y_true_text, y_pred_text, test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821cdb2-f60b-4ad2-8db8-42612fe4b083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bbedc-96cd-4950-8764-79d10273b4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendomainchat",
   "language": "python",
   "name": "opendomainchat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
