{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv with annotations from all annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated documents: 665\n",
      "Number of annotated documents: 652\n"
     ]
    }
   ],
   "source": [
    "main_files = glob.glob('../data/Bete_main/annotation/*/*.tsv')\n",
    "nutrition_files = glob.glob('../data/Bete_nutrition/annotation/*/*.tsv')\n",
    "main_files.sort()\n",
    "nutrition_files.sort()\n",
    "all_files = {'main': main_files, 'nutrition': nutrition_files}\n",
    "new_csv_file = []\n",
    "for data_name, data_files in all_files.items():\n",
    "    print(f'Number of annotated documents: {len(data_files)}')\n",
    "    for cur_file in data_files:\n",
    "        annotator_name = cur_file.split(os.sep)[-1]\n",
    "        document_name = cur_file.split(os.sep)[-2]\n",
    "        with open(cur_file, encoding=\"utf8\") as f:\n",
    "            body = False\n",
    "            for line in f:\n",
    "                if body:\n",
    "                    line_list = line.strip('\\n\\t ').split('\\t')\n",
    "                    cur_csv_list = [f'{data_name}_{document_name}', annotator_name] + line_list\n",
    "                    if len(cur_csv_list) < 7:\n",
    "                        for i in range(7 - len(cur_csv_list)):\n",
    "                            cur_csv_list.append('_')\n",
    "                    new_csv_file.append(cur_csv_list)\n",
    "    #                 print(cur_csv_list)\n",
    "                if line.startswith('#Text'):\n",
    "                    body = True\n",
    "df = pd.DataFrame(new_csv_file, columns=['File', 'Annotator', 'Token ID', 'Token position', 'Token', 'Entity', 'Relation', 'Relation ID'])\n",
    "df.to_csv('../data/all_annotated_dataset_2023_01_18.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate inter-annotator agreement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute entities agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ent(ent: str):\n",
    "    upd_entity = ent\n",
    "    if ent.endswith(']'):\n",
    "        upd_entity = ent.split('[')[0]\n",
    "    return upd_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of main documents: 304\n",
      "Number of nutrition documents: 258\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       Complication       0.75      0.76      0.76       246\n",
      "       DiabetesType       0.93      0.95      0.94        58\n",
      "               Dose       0.72      0.78      0.75        50\n",
      "           Duration       0.73      0.73      0.73        15\n",
      "               Food       0.99      1.00      0.99      1588\n",
      "       GlucoseValue       0.80      0.82      0.81       240\n",
      "            Insulin       0.82      0.50      0.62        36\n",
      "         Medication       0.85      0.85      0.85        34\n",
      "NonMedicalTreatment       0.94      0.95      0.95       691\n",
      "                Set       0.86      0.88      0.87        64\n",
      "            Symptom       0.95      0.92      0.93       687\n",
      "               Test       0.94      0.75      0.83        40\n",
      "               Time       0.92      0.97      0.95       127\n",
      "\n",
      "          micro avg       0.93      0.93      0.93      3876\n",
      "          macro avg       0.86      0.84      0.84      3876\n",
      "       weighted avg       0.93      0.93      0.93      3876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_files = glob.glob('../data/Bete_main/annotation/*')\n",
    "nutrition_files = glob.glob('../data/Bete_nutrition/annotation/*')\n",
    "main_files.sort()\n",
    "nutrition_files.sort()\n",
    "all_files = {'main': main_files, 'nutrition': nutrition_files}\n",
    "df = pd.read_csv('../data/all_annotated_dataset_2023_01_18.csv')\n",
    "ent1_full, ent2_full = [], []\n",
    "entity_map, entity_to_token_count, relation_map = {}, {}, {}\n",
    "for data_name, data_files in all_files.items():\n",
    "    print(f\"Number of {data_name} documents: {len(data_files)}\")\n",
    "    for cur_file in data_files:\n",
    "        document_name = cur_file.split(os.sep)[-1]\n",
    "        file_df = df[df['File'] == f'{data_name}_{document_name}']\n",
    "        annotator_set = set(file_df['Annotator'])\n",
    "        # print(document_name)\n",
    "        # print(annotator_set)\n",
    "        ann_tuple = []\n",
    "        for annot in annotator_set:\n",
    "            annotator_df = file_df[file_df['Annotator'] == annot]\n",
    "            count_entity = 0\n",
    "            for ann_ent in annotator_df['Entity']:\n",
    "                if ann_ent != '_':\n",
    "                    count_entity += 1\n",
    "            ann_tuple.append((annot, count_entity))\n",
    "        sorted_list = sorted(ann_tuple, key=lambda v: (-v[1], v[0]))\n",
    "        if len(sorted_list) >= 2:\n",
    "            ann1 = file_df[file_df['Annotator'] == sorted_list[0][0]]\n",
    "            ann2 = file_df[file_df['Annotator'] == sorted_list[1][0]]\n",
    "            ent1_list, ent2_list = [], []\n",
    "            for ent1, ent2 in zip(ann1['Entity'], ann2['Entity']):\n",
    "                if parse_ent(ent1) != '_' and parse_ent(ent2) != '_' and parse_ent(ent1) != '*' and parse_ent(ent2) != '*':\n",
    "                # if (parse_ent(ent1) != '_' or parse_ent(ent2) != '_') and parse_ent(ent1) != '*' and parse_ent(ent2) != '*':\n",
    "                    ent1_list.append(parse_ent(ent1))\n",
    "                    ent2_list.append(parse_ent(ent2))\n",
    "            ent1_full.extend(ent1_list)\n",
    "            ent2_full.extend(ent2_list)\n",
    "print(classification_report(ent1_full, ent2_full, labels=['Complication',\n",
    " 'DiabetesType',\n",
    " 'Dose',\n",
    " 'Duration',\n",
    " 'Food',\n",
    " 'GlucoseValue',\n",
    " 'Insulin',\n",
    " 'Medication',\n",
    " 'NonMedicalTreatment',\n",
    " 'Set',\n",
    " 'Symptom',\n",
    " 'Test',\n",
    " 'Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9119127934162823"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(ent1_full, ent2_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute relation agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rel(rel: str):\n",
    "    upd_rel = rel\n",
    "    if '|' in rel:\n",
    "        upd_rel = rel.split('|')[0]\n",
    "    return upd_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of main documents: 304\n",
      "Number of nutrition documents: 258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      causes       0.70      0.49      0.58       166\n",
      "    prevents       0.56      0.71      0.63         7\n",
      "      treats       0.92      0.88      0.90        26\n",
      "         has       0.39      0.60      0.47        85\n",
      "   diagnoses       1.00      0.86      0.92         7\n",
      " complicates       0.17      0.50      0.25         2\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       293\n",
      "   macro avg       0.62      0.67      0.62       293\n",
      "weighted avg       0.63      0.57      0.58       293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_files = glob.glob('../data/Bete_main/annotation/*')\n",
    "nutrition_files = glob.glob('../data/Bete_nutrition/annotation/*')\n",
    "main_files.sort()\n",
    "nutrition_files.sort()\n",
    "all_files = {'main': main_files, 'nutrition': nutrition_files}\n",
    "df = pd.read_csv('../data/all_annotated_dataset_2023_01_18.csv')\n",
    "rel1_full, rel2_full = [], []\n",
    "entity_map, entity_to_token_count, relation_map = {}, {}, {}\n",
    "for data_name, data_files in all_files.items():\n",
    "    print(f\"Number of {data_name} documents: {len(data_files)}\")\n",
    "    for cur_file in data_files:\n",
    "        document_name = cur_file.split(os.sep)[-1]\n",
    "        file_df = df[df['File'] == f'{data_name}_{document_name}']\n",
    "        annotator_set = set(file_df['Annotator'])\n",
    "        # print(document_name)\n",
    "        # print(annotator_set)\n",
    "        ann_tuple = []\n",
    "        for annot in annotator_set:\n",
    "            annotator_df = file_df[file_df['Annotator'] == annot]\n",
    "            count_relation = 0\n",
    "            for ann_ent in annotator_df['Relation']:\n",
    "                if ann_ent != '_':\n",
    "                    count_relation += 1\n",
    "            ann_tuple.append((annot, count_relation))\n",
    "        sorted_list = sorted(ann_tuple, key=lambda v: (-v[1], v[0]))\n",
    "        if len(sorted_list) >= 2:\n",
    "            ann1 = file_df[file_df['Annotator'] == sorted_list[0][0]]\n",
    "            ann2 = file_df[file_df['Annotator'] == sorted_list[1][0]]\n",
    "            ent1_list, ent2_list = [], []\n",
    "            for ent1, ent2 in zip(ann1['Relation'], ann2['Relation']):\n",
    "                if parse_rel(ent1) != '_' and parse_rel(ent2) != '_' and parse_rel(ent1) != '*' and parse_rel(ent2) != '*':\n",
    "                # if (parse_rel(ent1) != '_' or parse_rel(ent2) != '_') and parse_rel(ent1) != '*' and parse_rel(ent2) != '*':\n",
    "                    ent1_list.append(parse_rel(ent1))\n",
    "                    ent2_list.append(parse_rel(ent2))\n",
    "            rel1_full.extend(ent1_list)\n",
    "            rel2_full.extend(ent2_list)\n",
    "print(classification_report(rel1_full, rel2_full, labels=['causes', 'prevents', 'treats', 'has', 'diagnoses', 'complicates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32552972416409254"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(rel1_full, rel2_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv with all annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated documents: 304\n",
      "Number of annotated documents: 201\n"
     ]
    }
   ],
   "source": [
    "# cur_path = os.path.abspath(os.getcwd())\n",
    "# data_path = os.path.join(cur_path, '..\\\\data\\\\Dia-Bete\\\\Bete_main\\\\curation\\\\*\\\\*')\n",
    "main_files = glob.glob('../data/Bete_main/curation/*/*')\n",
    "nutrition_files = glob.glob('../data/Bete_nutrition/curation/*/*')\n",
    "main_files.sort()\n",
    "nutrition_files.sort()\n",
    "all_files = {'main': main_files, 'nutrition': nutrition_files}\n",
    "new_csv_file = []\n",
    "for data_name, data_files in all_files.items():\n",
    "    print(f'Number of annotated documents: {len(data_files)}')\n",
    "    for cur_file in data_files:\n",
    "        document_name = cur_file.split('/')[-2]\n",
    "        with open(cur_file, encoding=\"utf8\") as f:\n",
    "            body = False\n",
    "            for line in f:\n",
    "                if body:\n",
    "                    line_list = line.strip('\\n\\t ').split('\\t')\n",
    "                    cur_csv_list = [data_name, document_name] + line_list\n",
    "                    if len(cur_csv_list) < 7:\n",
    "                        for i in range(7 - len(cur_csv_list)):\n",
    "                            cur_csv_list.append('_')\n",
    "                    new_csv_file.append(cur_csv_list)\n",
    "    #                 print(cur_csv_list)\n",
    "                if line.startswith('#Text'):\n",
    "                    body = True\n",
    "df = pd.DataFrame(new_csv_file, columns=['Data', 'File', 'Token ID', 'Token position', 'Token', 'Entity', 'Relation', 'Relation ID'])\n",
    "df.to_csv('../data/curated_dataset_2022_01_07.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse in this format\n",
    "'''\n",
    "{\n",
    "        \"keyphrases\":{\n",
    "            \"1\":{\n",
    "                \"attributes\":[],\n",
    "                \"error\":false,\n",
    "                \"id\":1,\n",
    "                \"idxs\":[\n",
    "                    2,\n",
    "                    3,\n",
    "                    4,\n",
    "                    5,\n",
    "                    6\n",
    "                ],\n",
    "                \"label\":\"Concept\",\n",
    "                \"spans\":[\n",
    "                    [\n",
    "                        4,\n",
    "                        12\n",
    "                    ],\n",
    "                    [\n",
    "                        13,\n",
    "                        20\n",
    "                    ]\n",
    "                ],\n",
    "                \"text\":\"gl\\u00f3bulos blancos\",\n",
    "                \"tokens\":[\n",
    "                    \"gl\\u00f3bulos\",\n",
    "                    \"blancos\"\n",
    "                ]\n",
    "            },\n",
    "            \"2\":{\n",
    "                \"attributes\":[],\n",
    "                \"error\":false,\n",
    "                \"id\":2,\n",
    "                \"idxs\":[\n",
    "                    7,\n",
    "                    8\n",
    "                ],\n",
    "                \"label\":\"Action\",\n",
    "                \"spans\":[\n",
    "                    [\n",
    "                        21,\n",
    "                        27\n",
    "                    ]\n",
    "                ],\n",
    "                \"text\":\"ayudan\",\n",
    "                \"tokens\":[\n",
    "                    \"ayudan\"\n",
    "                ]\n",
    "            },\n",
    "            \"3\":{\n",
    "                \"attributes\":[],\n",
    "                \"error\":false,\n",
    "                \"id\":3,\n",
    "                \"idxs\":[\n",
    "                    11\n",
    "                ],\n",
    "                \"label\":\"Concept\",\n",
    "                \"spans\":[\n",
    "                    [\n",
    "                        33,\n",
    "                        42\n",
    "                    ]\n",
    "                ],\n",
    "                \"text\":\"organismo\",\n",
    "                \"tokens\":[\n",
    "                    \"organismo\"\n",
    "                ]\n",
    "            },\n",
    "            \"4\":{\n",
    "                \"attributes\":[],\n",
    "                \"error\":false,\n",
    "                \"id\":4,\n",
    "                \"idxs\":[\n",
    "                    13,\n",
    "                    14\n",
    "                ],\n",
    "                \"label\":\"Action\",\n",
    "                \"spans\":[\n",
    "                    [\n",
    "                        45,\n",
    "                        53\n",
    "                    ]\n",
    "                ],\n",
    "                \"text\":\"combatir\",\n",
    "                \"tokens\":[\n",
    "                    \"combatir\"\n",
    "                ]\n",
    "            },\n",
    "            \"5\":{\n",
    "                \"attributes\":[],\n",
    "                \"error\":false,\n",
    "                \"id\":5,\n",
    "                \"idxs\":[\n",
    "                    15,\n",
    "                    16,\n",
    "                    17\n",
    "                ],\n",
    "                \"label\":\"Concept\",\n",
    "                \"spans\":[\n",
    "                    [\n",
    "                        54,\n",
    "                        65\n",
    "                    ]\n",
    "                ],\n",
    "                \"text\":\"infecciones\",\n",
    "                \"tokens\":[\n",
    "                    \"infecciones\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"relations\":[\n",
    "            {\n",
    "                \"arg1\":4,\n",
    "                \"arg2\":3,\n",
    "                \"label\":\"subject\"\n",
    "            },\n",
    "            {\n",
    "                \"arg1\":4,\n",
    "                \"arg2\":5,\n",
    "                \"label\":\"target\"\n",
    "            },\n",
    "            {\n",
    "                \"arg1\":2,\n",
    "                \"arg2\":1,\n",
    "                \"label\":\"subject\"\n",
    "            },\n",
    "            {\n",
    "                \"arg1\":2,\n",
    "                \"arg2\":4,\n",
    "                \"label\":\"target\"\n",
    "            }\n",
    "        ],\n",
    "        \"text\":\"Los gl\\u00f3bulos blancos ayudan a su organismo a combatir infecciones.\",\n",
    "        \"tokens\":[\n",
    "            \"[CLS]\",\n",
    "            \"Los\",\n",
    "            \"g\",\n",
    "            \"##l\\u00f3\",\n",
    "            \"##bulo\",\n",
    "            \"##s\",\n",
    "            \"blancos\",\n",
    "            \"ayuda\",\n",
    "            \"##n\",\n",
    "            \"a\",\n",
    "            \"su\",\n",
    "            \"organismo\",\n",
    "            \"a\",\n",
    "            \"combat\",\n",
    "            \"##ir\",\n",
    "            \"in\",\n",
    "            \"##fe\",\n",
    "            \"##cciones\",\n",
    "            \".\",\n",
    "            \"[SEP]\"\n",
    "        ]\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba23d1352a4aba770e0097968d0977684913ecdc276f60b28ba24b7c7e944000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
